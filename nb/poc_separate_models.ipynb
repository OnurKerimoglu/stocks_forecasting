{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24ab94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "import kaggle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from statsmodels.tsa.deterministic import DeterministicProcess, CalendarFourier\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "rootpath = os.path.dirname(os.getcwd())\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(rootpath, 'src'))\n",
    "sys.path.insert(0, module_path)\n",
    "from style import plot_params  # in src folder\n",
    "\n",
    "\n",
    "print(f'rootpath: {rootpath}')\n",
    "datasetname = 'world-stock-prices-daily-updating'\n",
    "datapath = os.path.join(rootpath, 'data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786fca87",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5758570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ticker(df_clean, ticker, requiredrecords=500, datapath=None, write=False,):\n",
    "    if type(ticker) is not str:\n",
    "        raise TypeError('ticker must be a string')\n",
    "    print(f'Extracting for ticker: {ticker}')\n",
    "    df_clean_sample = df_clean[\n",
    "        (df_clean['Ticker'].isin([ticker])) #& \n",
    "        # (df_clean['Date'] >= date(2025, 1, 1))\n",
    "        ].copy()\n",
    "    # set date as index\n",
    "    df_clean_sample.set_index('Date', inplace=True)\n",
    "    # df_clean_sample = df_clean_sample.resample('D').mean()\n",
    "    df_clean_sample.index = df_clean_sample.index.normalize()\n",
    "    # drop unnecessary coluns\n",
    "    df_clean_sample.drop(columns=['Ticker'], inplace=True)\n",
    "    # drop rows with nans\n",
    "    df_clean_sample = df_clean_sample.dropna()\n",
    "    df_clean_sample = df_clean_sample.sort_values('Date', ascending=False)\n",
    "    # take only the requested number of records from the latest period\n",
    "    df_clean_sample = df_clean_sample.head(requiredrecords)\n",
    "    print(f'Extracted sample shape: {df_clean_sample.shape}')\n",
    "    \n",
    "    if write:\n",
    "        clean_sample_fpath_full = os.path.join(datapath, f'clean_sample_{ticker}.csv')\n",
    "        df_clean_sample.to_csv(clean_sample_fpath_full, index=False)\n",
    "        print(f'Wrote sample to: {clean_sample_fpath_full}')\n",
    "    return df_clean_sample\n",
    "\n",
    "def plot_seasonal_composition(df, feature):\n",
    "    df=df.copy()\n",
    "    if df.index[-1]<df.index[0]:\n",
    "        #flip upside down\n",
    "        df=df.iloc[::-1]\n",
    "    decomposition = seasonal_decompose(\n",
    "        df[feature], # .asfreq('D'),\n",
    "        model='additive',\n",
    "        period=5\n",
    "        )\n",
    "    fig = decomposition.plot()\n",
    "    fig.set_size_inches(15, 10)\n",
    "    # plt.show()\n",
    "    # plt.title(feature)\n",
    "\n",
    "def plot_periodogram(ts, detrend='linear', ax=None):\n",
    "    from scipy.signal import periodogram\n",
    "    fs = pd.Timedelta(\"365D\") / pd.Timedelta(\"1D\")\n",
    "    freqencies, spectrum = periodogram(\n",
    "        ts,\n",
    "        fs=fs,\n",
    "        detrend=detrend,\n",
    "        window=\"boxcar\",\n",
    "        scaling='spectrum',\n",
    "    )\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "    ax.step(freqencies, spectrum, color=\"purple\")\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_xticks([1, 2, 4, 6, 12, 26, 52, 104])\n",
    "    ax.set_xticklabels(\n",
    "        [\n",
    "            \"Annual (1)\",\n",
    "            \"Semiannual (2)\",\n",
    "            \"Quarterly (4)\",\n",
    "            \"Bimonthly (6)\",\n",
    "            \"Monthly (12)\",\n",
    "            \"Biweekly (26)\",\n",
    "            \"Weekly (52)\",\n",
    "            \"Semiweekly (104)\",\n",
    "        ],\n",
    "        rotation=30,\n",
    "    )\n",
    "    ax.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n",
    "    ax.set_ylabel(\"Variance\")\n",
    "    ax.set_title(\"Periodogram\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbebb5f",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c54c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(datapath, exist_ok=True)\n",
    "if not os.path.exists(os.path.join(datapath, datasetname)):\n",
    "    kaggle.api.dataset_download_files(\n",
    "        dataset=f'nelgiriyewithana/{datasetname}',\n",
    "        path=datapath,\n",
    "        unzip=True)\n",
    "else:\n",
    "    print('Raw data already found in location {}'.format(datapath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d142502",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_fpath = os.listdir(os.path.join(datapath, datasetname))[0]\n",
    "raw_fpath_full = os.path.join(datapath, datasetname, raw_fpath)\n",
    "\n",
    "print(f'reading raw data from: {raw_fpath_full}')\n",
    "df_raw = pd.read_csv(raw_fpath_full)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb8c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48796a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_raw.copy()\n",
    "df_clean['Date'] = pd.to_datetime(df_clean['Date'], utc=True).dt.tz_convert(None)\n",
    "# df_clean['Date'] = df_clean['Date'].dt.date\n",
    "df_clean.drop_duplicates(subset=['Date', 'Ticker'], keep='first', inplace=True)\n",
    "df_clean = df_clean[['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Ticker']]\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183ccfca",
   "metadata": {},
   "source": [
    "## Example Ticker 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7aa948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and compute base features\n",
    "df = extract_ticker(df_clean, 'AAPL', requiredrecords=500, write=False) # datapath=datapath\n",
    "df['rel_return'] = (df['Close'] - df['Open']) / df['Open']\n",
    "df['volatility'] = (df['High'] - df['Low']) / ((df['High'] + df['Low']) / 2)\n",
    "df['dollar_vol'] = df['Volume'] * ((df['Open'] + df['Close']) / 2)\n",
    "df.drop(columns=['Open', 'High', 'Low', 'Volume'], inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65cf858",
   "metadata": {},
   "source": [
    "### Analysis of Time Series Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5db3571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal decomposition\n",
    "plot_seasonal_composition(df, 'Close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b80aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_periodogram(df['Close'], detrend='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e799bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a trend\n",
    "y = df['Close'].copy()\n",
    "dp = DeterministicProcess(\n",
    "    index = y.index,\n",
    "    order=3\n",
    ")\n",
    "\n",
    "# YOUR CODE HERE: Create the feature set for the dates given in y.index\n",
    "X = dp.in_sample()\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "y_pred = pd.Series(model.predict(X), index=X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad50ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Close'].plot(**plot_params)\n",
    "y_pred.plot(**plot_params, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab719ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_resid = y-y_pred\n",
    "y_resid.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db72aca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_periodogram(y-y_pred, detrend='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99e68bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5eaa73da",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d594beca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Close'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a2e314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "all_days = pd.Series(df.index.sort_values().values)\n",
    "split_date = all_days[int(len(all_days) * 0.8)]\n",
    "train_df = df[df.index < split_date].copy()\n",
    "test_df  = df[df.index >=  split_date].copy()\n",
    "print(f'Train shape: {train_df.shape}, Test shape: {test_df.shape}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stocks_forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
